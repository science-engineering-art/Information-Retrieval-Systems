% This is LLNCS.DOC the documentation file of
% the LaTeX2e class from Springer-Verlag
% for Lecture Notes in Computer Science, version 2.4
\documentclass{llncs}
\usepackage{Proyecto_Final_Sherlock}
\usepackage{color}


\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{amsfonts}
\usepackage{todonotes}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}

%\usepackage{amsthm}
\usepackage{amsmath}
\newtheorem{defn}[theorem]{Definici\'on}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage[spanish]{babel}

% Keywords command
\providecommand{\keywords}[1]
{
	\small	
	\textbf{\textit{Palabras clave --- }} #1
}

\begin{document}
	\markboth{Sistemas de Recuperaci\'on de Informaci\'on}{	Motor de b\'usqueda: \textbf{Sherlock}}
	\thispagestyle{empty}
	\begin{flushleft}
		\LARGE\bfseries Sistemas de Recuperaci\'on de Informaci\'on\\[2cm]
	\end{flushleft}
	\rule{\textwidth}{1pt}
	\vspace{2pt}
	\begin{flushright}
		\Huge
		\begin{tabular}{@{}l}
			Motor de \\
			b\'usqueda:\\
			\textbf{Sherlock}
			\includegraphics[height=1em]{sherlock.png}\\[6pt]
%			Modelos de\\ 
%			recuperaci\'on de\\ 
%			informaci\'on\\[6pt]
		\end{tabular}
	\end{flushright}
	\rule{\textwidth}{1pt}
	\vfill
	\begin{flushleft}
		\large\itshape
		\begin{tabular}{@{}l}
			{\large\upshape\bfseries Autores}\\[8pt]
			Laura Victoria Riera P\'erez\\[5pt]
			Leandro Rodr\'iguez Llosa\\[5pt]
			Marcos Manuel Tirador del Riego
		\end{tabular}
	\end{flushleft}
	
	\newpage
	\pagenumbering{gobble}
	\begin{abstract}
		Se abordan los aspectos principales de una posible implementaci\'on del modelo vectorial cl\'asico.
		
		\vspace{1em}
		\keywords{recuperaci\'on de informaci\'on (RI) \textbf{$\cdot$} modelo vectorial}
	\end{abstract} 
	\thispagestyle{empty}
	
	
	\newpage
	\pagenumbering{gobble}
	\tableofcontents
	\thispagestyle{empty}
	
	\newpage
	\pagenumbering{arabic}
	
	\section{Introducci\'on}
	
	En la actualidad, con el inmenso crecimiento del internet, se convierte en un reto cada vez mayor el manejo de la información, su recuperaci\'on y la extracci\'on de conocimiento de ella. Por esto, es de especial interes\'es la creaci\'on de algoritmos que ayuden a su manipulaci\'on. En este informe se expondr\'an algunas ideas importantes seguidas a la hora de implementar un modelo de recuperaci\'on de informaci\'on cl\'asico: el modelo vectorial.
	
	\section{Modelaci\'on del problema}
	
	\subsection{Documentos}
	Para el desarrollo de este Sistema de Recuperaci\'on de la Informaci\'on modelamos un documento como un objeto que contiene al menos dos propiedades, un \texttt{doc\_id} que identifica de manera \'unica a un documento dentro del conjunto de documentos del dataset en cuesti\'on; y un \texttt{text} que corresponde con el texto de este. Tambi\'en puede tener otras propiedades, por ejemplo: \texttt{title}, \texttt{author}; pero eso depende de la riqueza del dataset que provee el paquete de Python \texttt{ir\_datasets} (ver \cite{B3}).
	
	Como el texto de un documento es inc\'omodo de manipular por venir en forma de \texttt{string}, este se toqueniza y convierte en una lista de t\'erminos indexados normalizados. Esto se logra haciendo uso del paquete de Python \texttt{re} (referirse a \cite{B4}) que proporciona una colecci\'on de funciones que facilitan el trabajo con expresiones regulares. 
	
	\subsection{Normalizaci\'on de un t\'ermino}
	
	Es importante destacar algunas asunciones que se tuvieron en cuenta en el proceso de toquenizaci\'on. No se considera relevante la diferenciación entre una letra may\'uscula y una min\'uscula, ya que, en la mayoría de los casos, el significado sem\'antico que expresan es el mismo. Para reducir algunos errores ortográficos, y que esto no perjudique la recuperaci\'on de un documento importante, se considera que las tildes no diferencian una palabra de otra. Se conoce que esto \'ultimo no es cierto en el español, pero por el momento se est\'a trabajando con textos en ingl\'es.
	
	Resumiendo, se trata de llevar todos los t\'erminos a cadenas de caracteres que contienen letras min\'usculas o n\'umeros.
	
	\subsection{Corpus}
	
	Un corpus no es más que el conjunto de documentos de un dataset, toquenizados y normalizados.
	
	\subsection{Modelo base}
	
	Se define un modelo base como un concepto abstracto, que engloba los comportamientos comunes que debe tener cada modelo de recuperaci\'on de informaci\'on. 
	
	Cada instancia de un modelo tiene un corpus asociado a este, sobre el cual se hacen las b\'usquedas. Se deja en manos del programador qu\'e preprocesamientos hacer con el corpus, en dependencia del modelo que se est\'e implementando. 
	
	\section{Modelo vectorial}
	
	\subsection{Preprocesamiento}
	
	Seg\'un la f\'ormula de similitud del coseno (\cite[\emph{Ecuaci\'on}~(6.10)]{B1}), se puede notar que el aporte de un documento a la f\'ormula se mantiene invariante para todas las consultas, ya que este solo depende del vector que representa al documento, el cual es independiente de la consulta. Por tanto, como el corpus sobre el cu\'al se va a recuperar informaci\'on se mantendr\'a est\'atico, se calcula el peso de cada t\'ermino en cada documento para as\'i poder utilizarlo en cada consulta que se realice.
	
	Para calcular el peso de cada t\'ermino en cada documento seg\'un \cite[Ecuaci\'on (2.3)]{B1}, primero se necesita calcular las frecuencias normalizadas de los t\'erminos en cada documento (TF \cite[Ecuaci\'on (2.1)]{B2}), y la frecuencia de ocurrencia de cada t\'ermino dentro de todos los documentos del corpus (IDF \cite[Ecuaci\'on(2.2)]{B2}).
	
	\subsection{Recuperación de documentos}
	
	La primera fase es similar a la del preprocesamiento de los documentos del corpus. Lo primero que se hace es toquenizar y normalizar la consulta. Luego se hallan los TFs, y se calcula el peso de cada t\'ermino en la consulta. Para el c\'alculo de los pesos de cada t\'ermino  se utiliza la medida de suavizado \texttt{a = 0.4} para amortizar la contribuci\'on de la frecuencia del t\'ermino (ver \cite[ecuaci\'on (2.4)]{B2}). Por \'ultimo se halla la cercan\'ia entre el vector consulta y cada vector documento, utilizando la similitud del coseno entre los vectores seg\'un \cite[Ecuaci\'on 6.10]{B1}, y se hace un ranking teniendo este valor calculado.
	
	
	\section{Modelo Fuzzy}
	
		En el modelo booleano se representan las consultas y documentos como conjuntos de palabras. Al determinar que un documento es relevante a una consulta si y solo si tiene una coincidencia exacta de las palabras en la consulta solamente nos acercamos parcialmente al contenido sem\'antico real de los contenidos. Una alternativa ser\'ia definir un conjunto difuso por cada palabra de la consulta y determinar un grado de pertenencia de cada documento a este conjunto, para luego basado en esto, poder asignar un grado de relevancia de cada documento a la consulta dada. Esta es la idea b\'asica detr\'as de distintos modelos de recuperaci\'on de la informaci\'on basados en conjuntos difusos. 
		
		Se presentan a continuaci\'on algunos conceptos de la teor\'ia de conjuntos difusos necesario para entender el modelo implementado que se describe en esta secci\'on.
		\begin{defn} (\cite[Section~2.6.1]{B2}) Un conjunto difuso $A$ de un universo de discurso $U$ est\'a caracterizado por una funci\'on de membres\'ia $\mu_A : U \rightarrow [0,1]$ que asocia a cada elemento $u \in U$ un n\'umero $\mu_A(u)$ en el intervalo $[0,1].$
		\end{defn}
		Las tres operaciones m\'as usadas de conjuntos difusos se definen a continuaci\'on.
		\begin{defn}(\cite[Section~2.6.1]{B2})
			Sea $U$ el universo de discurso, $A$ y $B$ dos conjuntos difusos de $U$ y $\overline{A}$ el complemento de $A$ en $U$. Sea adem\'as un elemento $u \in U$. Entonces, 
			\begin{align*}
				\mu_{\overline{A}}(u) &= 1- \mu_A(u) \\
				\mu_{A \cup B}(u) &= \max(\mu_A(u), \mu_B(u))  \\
				\mu_{A\cap B}(u) &= \min(\mu_A(u), \mu_B(u)).
			\end{align*}
			
		\end{defn}
	
	
	\subsection{Descripci\'on del modelo usado}
	
	El modelo fuzzy que se seleccion\'o para su implementaci\'on fue propueto por Ogawa, Morita y Kobayashi en \cite{B5}.
	
	\section{Conclusiones}
	
	Este trabajo presenta una propuesta para la modelaci\'on del problema de recuperaci\'on de informaci\'on. Se detallaron aspectos generales del modelo vectorial cl\'asico, as\'i como decisiones de dise\~no espec\'ificas de la propia interpretaci\'on del problema.
	
	\begin{thebibliography}{20}
		\bibitem{B1} Maning C. D.: \emph{An Introduction To Information Retrieval} (2009).
		\bibitem{B2} Ricardo Baeza-Yates: \emph{Modern Information Retrieval} (1999).
		\bibitem{B3} Documentaci\'on oficial: \emph{https://ir-datasets.com/index.html}
		\bibitem{B4} Documentaci\'on oficial: \emph{https://docs.python.org/3/library/re.html}
		
		\bibitem{B5} Y. Ogawa, T. Morita y K. Kobayashi. A fuzzy document retrieval system using the keyword connection matrix and a learning method. Fuzzy Sets and Systems, 39:163-179, 1991.
	\end{thebibliography}
	
\end{document}
